---
title: 'OpenGL 2 了解计算机三维渲染过程'
date: 2017-07-23 19:06:52
categories: "技术积累" #文章分類目錄 可以省略
tags:
    - opengl
---

这篇文章其实是阅读了谷歌排名第一的OpenGL教程的入门部分总结的读后感。
[原文在这里][1], [中文版翻译在这里][2]，[原文作者在这里][3]

[1]: https://learnopengl.com/
[2]: https://learnopengl-cn.github.io/
[3]: https://www.patreon.com/learnopengl

以前经常有大厚本的OpenGL红宝书啦、24入门啦、3个月快速开发啦这些东西，但是真正感觉还是这次看的资料有用一些。这一份东西把三维图形学从里到外讲了个透。

看这个教程的入门部分，我觉得最关键的是对显卡渲染流程的了解，总结在本文中供之后借鉴。借用一下教程中的图，是下面这个样子的：


![](http://7yusyv.com1.z0.glb.clouddn.com/2017-07/pipeline.png)

## 1. VERTEX DATA

VERTEX DATA中可包含任意你需要的内容，包括模型顶点坐标、顶点属性（颜色、材质、纹理坐标、<span style="color:#de2020">任意其他属性</span>）。有了这些数据，可以在渲染的过程中做很多的事情。

## 2. VERTEX SHADER

这个步骤对每个参与渲染的顶点都做一次处理（SHADER其实就是一个小程序，其输入就是这每一个对象）。

这里只要出现了SHADER，就说明这个是我们可以控制的部分了，这个过程可以做两类事情：
    生成渲染需要的顶点坐标，这个顶点坐标根据渲染的类型不同含义不同。如果是三角形渲染方式，那么每3个坐标为一个三角形的三个定点，如果是线段渲染，那每两个坐标为线段的两端点。
    进行其他处理，将数据传递给之后的SHADER。

在这一步骤中，通过VERTEX SHADER进行顶点生成的目标是将需要可视化的内容放到(-1,-1,-1)到(1,1,1)中。及标准化设备坐标(Normalized Device Coordinate, NDC)中。形象一点说，OpenGL其实就是一个2X2X2的鱼缸，OpenGL渲染过程就是把鱼缸里的东西全部压扁到鱼缸的一个面形成图像。为了实现我们需要的视角，我们需要透过种种坐标变换，将实际三维空间按我们定义的视角映射到这个2X2X2的标准设备空间中。

## 3. SHAPE ASSEMBLY

就是将步骤1中生成的顶点按渲染方式组装成几何体，比如，如果渲染方式是三角形，这里会将每3个顶点组装成一个三角形。

## 4. GEOMETRY SHADER

这个步骤对每个前面步骤组装的集合体都做一个处理。

GEOMETRY SHADER默认可不设置，那么就会直接把ASSEMBLE后的SHAPE直接发给后面的步骤了。

GEOMETRY SHADER的输入就是前面ASSEMBLE后的个几何基本体（点/线段/三角形)。其可做的操作就是添加任意类型的几何基本体到当前的图形中，并交给后面的步骤处理。

## 5. RASTERIZATION

在这个步骤，OpenGL底层自动对所有几何按照(-1,-1,-1)到(1,1,1)这个范围进行裁剪。并将所有的基本集合体映射到光栅上，形成一个个片段（可以理解为一个个像素点）。这每一个片段都将在下一步骤进行处理。

这每个片段都将包含在步骤1的VERTEX SHADER中输出的属性值。对于非顶点的图形位置，其属性值是其所在基本体各定点的属性值的线性插值。
比如三角形内部点的纹理坐标就是各顶点纹理坐标的插值。用户也可自定义一些属性，比如三角形各顶点的属性也可以就是其坐标，那么内部顶点的属性也就会处理成其真实坐标。

## 6. FRAGMENT SHADER

在这个步骤，对每个片段（可理解为像素点）进行处理，其输入就是VERTEX SHADER传来的属性。输出为一个4通道颜色信息。

## 7. TESETS AND BLENDING

根据深度等信息，将所有FRAGMENT混合成一张图像。

>Shader程序是由GLSL语言编写的子程序。这些子程序以字符串的形式传递给OpenGL的API，并由OpenGL的API进行编译、链接，并在三维渲染流程中被调用。Shader给予了程序员极大的自由度来操作三维渲染的过程。GLSL其实是在2004年才正式引入OpenGL 2.0的。具体可以参考[维基百科][4]。

[4]: https://en.wikipedia.org/wiki/OpenGL_Shading_Language
